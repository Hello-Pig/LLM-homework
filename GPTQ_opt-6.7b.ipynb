{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0788262-ae7a-4e62-8a74-84e9ab35b2dd",
   "metadata": {},
   "source": [
    "# Homework: 使用 GPTQ 算法量化 OPT-6.7B 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321bc681-89e0-44c8-ae9c-8e6cec34106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/LLM/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/root/miniconda3/envs/LLM/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]\n",
      "Quantizing model.decoder.layers blocks :   0%|          | 0/32 [00:00<?, ?it/s]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:13,  2.72s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:05<00:09,  2.50s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.42s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.39s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:12<00:02,  2.38s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   3%|▎         | 1/32 [00:21<11:14, 21.74s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   6%|▋         | 2/32 [00:43<10:45, 21.53s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.37s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.37s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.36s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.37s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.37s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.44s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   9%|▉         | 3/32 [01:04<10:22, 21.48s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.43s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  12%|█▎        | 4/32 [01:25<09:59, 21.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.43s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  16%|█▌        | 5/32 [01:47<09:36, 21.37s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  19%|█▉        | 6/32 [02:08<09:15, 21.37s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.44s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  22%|██▏       | 7/32 [02:29<08:53, 21.36s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.42s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  25%|██▌       | 8/32 [02:51<08:31, 21.33s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.42s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  28%|██▊       | 9/32 [03:12<08:10, 21.31s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.43s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  31%|███▏      | 10/32 [03:33<07:48, 21.31s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.42s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  34%|███▍      | 11/32 [03:54<07:27, 21.29s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.43s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  38%|███▊      | 12/32 [04:16<07:06, 21.30s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.36s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.44s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  41%|████      | 13/32 [04:37<06:45, 21.32s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.44s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  44%|████▍     | 14/32 [04:58<06:23, 21.32s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  47%|████▋     | 15/32 [05:20<06:02, 21.33s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  50%|█████     | 16/32 [05:41<05:41, 21.34s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  53%|█████▎    | 17/32 [06:03<05:20, 21.36s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  56%|█████▋    | 18/32 [06:24<04:59, 21.37s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  59%|█████▉    | 19/32 [06:45<04:38, 21.39s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  62%|██████▎   | 20/32 [07:07<04:16, 21.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.32s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  66%|██████▌   | 21/32 [07:28<03:55, 21.39s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  69%|██████▉   | 22/32 [07:50<03:33, 21.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  72%|███████▏  | 23/32 [08:11<03:12, 21.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.38s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.45s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  75%|███████▌  | 24/32 [08:32<02:51, 21.39s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.46s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  78%|███████▊  | 25/32 [08:54<02:29, 21.39s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:05,  2.58s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:12<00:02,  2.51s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.58s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  81%|████████▏ | 26/32 [09:16<02:09, 21.60s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.36s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  84%|████████▍ | 27/32 [09:37<01:47, 21.56s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.36s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.47s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  88%|████████▊ | 28/32 [09:59<01:26, 21.52s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  91%|█████████ | 29/32 [10:20<01:04, 21.50s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.48s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  94%|█████████▍| 30/32 [10:42<00:42, 21.50s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:07<00:07,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.36s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.37s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.50s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  97%|█████████▋| 31/32 [11:03<00:21, 21.53s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:02<00:11,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:04<00:09,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:06<00:06,  2.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:09<00:04,  2.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:11<00:02,  2.35s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:20<00:00,  4.49s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks : 100%|██████████| 32/32 [11:25<00:00, 21.42s/it]\n",
      "/root/miniconda3/envs/LLM/lib/python3.11/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig\n",
    "import torch\n",
    "\n",
    "model_name_or_path = \"facebook/opt-6.7b\"\n",
    "\n",
    "quantization_config = GPTQConfig(\n",
    "     bits=4, # 量化精度\n",
    "     group_size=128,\n",
    "     dataset=\"wikitext2\",\n",
    "     desc_act=False,\n",
    ")\n",
    "\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ac5c37-e492-4fc8-a089-45c5be6959ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存量化后的模型\n",
    "quant_model.save_pretrained(\"models/opt-6.7b-gptq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3d234-e9a2-4c0b-b4af-f514c1bb3076",
   "metadata": {},
   "source": [
    "**试试看量化后的模型，生成效果怎么样**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a701e48-c66b-4e8e-90bc-f092f167c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas! I'm glad to see you're still around.\n",
      "I'm still around, just not as active as I used to be.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "text = \"Merry Christmas! I'm glad to\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = quant_model.generate(**inputs, max_new_tokens=64)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65bbf9b8-e9d8-448a-9831-a35681d6d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从前，有一只霸王龙的结果,他们的结果是从前的结果的结果的结果的结果的结果的结果的结果的结果的结果的结果的结果的结果的结果的结果的结�\n"
     ]
    }
   ],
   "source": [
    "text = \"从前，有一只霸王龙\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "out = quant_model.generate(**inputs, max_new_tokens=128)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088d6c9-a2ab-4103-9d2c-ebd6b370f288",
   "metadata": {},
   "source": [
    "**看来只对英语效果还可以，中文就算了把，毕竟模型和训练数据主要还是英文为主**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
