{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0e6e63-641c-4d92-8f23-f9b0d15eaa6a",
   "metadata": {},
   "source": [
    "## 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db7524a-2cd5-415e-96f6-6ea2143f6da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/LLM/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8fded2-94a0-42bc-9dbc-cc445164fdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe5d8d6-c0ff-42b7-8cb4-e225f9dd7335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"Ah, Steak n Shake, you hit the spot after a night of drinking. Open 24 hours, drive thru or dine in, with wonderful, cheap greasy burgers, chicken fingers, breakfast sandwiches, and shoestring fries. You're faster (and cheaper!) than Eat N Park. Plus your employees wear those adorable bow ties. Granted, if we were at a fancy party, I might act like I don't know you, but deep down inside you know I heart you.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc64a5c-7980-45c6-8d19-01d72e2bd961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I went onto Hotwire the other day and booked a hotel that is suppose to be only 3 stars.  I didnt know the hotel but I had to keep it cheap and this place is what I got.  I am so lucky!  this place was amazing! The room was really clean, the staff is very helpful, the morning breakfast was pretty tasty and best of all it was really cheap in comparison to all of the other hotels in the area.  It was at least $100 less then the ones in the same area. \\nOh and there is a refrigerator and a microwave in the room!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>Pretty good. Lots of different choices. I forget which day of the weekend they have seafood but, I loved the crab legs that you can get sauteed with a bunch of herbs and spices. All types of foods. The dessert section is great too. They have hand scooped ice cream or soft served and bunch of other selections.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 star</td>\n",
       "      <td>I was a customer for over 20 years until they charged me $158 for a $40 over draft. The problem is, it took them 10 days to send me a letter to inform me that I over drafted and then charged me every day. Considering that you have my email and phone number it would've been nice of you to inform me immediately that my account was overdrawn. Customer service is a joke and I had to call twice and leave a message plus email them to get a call back. Go somewhere else. Congrats PNC you lost yourself a customer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Excellent Venezuelan food. Location is a Venezuelan style Arepera\\\"; the arepas are big, well stuffed and delicious. We ate the \\\"Hallacas\\\" today, it's a Venezuelan type of tamal, and a traditional Christmas dish, it was really good. Passion fruit juice is an a must. Arepa of Queso de Mano, Reina Pepiada, Carne Mechada, are excellent! \\nPlace is clean and has the \\\"Salto Angel\\\" waterfall painted on the wall at the back of the restaurant, very nice! Service is friendly and excellent! This is our place to eat when we go to Charlotte!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 star</td>\n",
       "      <td>What a horrible horrible place. They make you wait in line when nobody is inside the bar. Meanwhile, they let dozens of people in the front with no issue. They're trying to be LA or Vegas. Complete failure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>I am always an opened minded person and also can give the benefit of the doubt and also address credit when credit is due. So my last review about this place I was upset a little not because the food was bad or anything it was actually good but I am  always getting teased about being hispanic and not able to even eat the mild sauce from taco bell without sweating and panting with my tongue for a drink. Lol\\nBut I had ordered mild and received hot last time and wasn't pleased because I honestly at 4 wings and the rest sat in the fridge for a week before I threw them out. I had called and someone offered me 12 wings and I thought it was fair but I am not the type to really complain or go running to get free food like some people would do but needless to say I was contacted by vinnie and offered to replace my whole order and even a pizza. I offered to pay for the pizza because again I am not a free food person. I know nothing in this world is free unless it's your birthday then there is an exception. Ha ha ha\\nWell I met with vinnie and he was awesome and very friendly and approachable I got the pizza and wings and able to eat the wings this time it was amazing. Best wings I have had in years they were juicy and crunchy and not small. I have been to some places where the wings are so small you get like one and a half bite of it but these wings are huge and the pizza that I was able to try for the first time was amazing as well. The cheese was flowing and piping hot and the sauce has to be a secret recipe past down from a family genius because it was perfect and not too over spiced or sweet. I am so glad he contacted me to try it out again and I know that our family Friday night pizza will be ordered from this place going forward in the future.  My kids even ate the crust and not sure about other people's kids but for mine to eat the crust it's nothing short of a miracle. Awesome food and great people and I will continue to be a repeat customer and I think that if you are reading reviews to figure which pizza place to try then look no further because this place is not expensive, delicious and will feed the whole family for under 25 bucks. Can't beat it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>So I went here last night and I have got to tell you that even though I am getting more frugal with handing out my 5 stars... but after the \\\"Smoked Pulled Pork Sliders\\\" this place is definitely deserving of 5 stars ................... I had brunch here I believe a couple of Sunday's ago and it was one of those bloody Mary therapy mornings and they came through with flying colors I had the corn beef Benedict and it was just unbelievable very hard to describe but when something just works and seems to come together in perfect harmony it just has to be praised....... the only and I do mean only thing I can complain about is size,....... portions and seating area are to small but that in itself is a testament to the quality of  their food leaves you wanting more and needing more room for the masses anyway I think I'm rambling now so until next time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 stars</td>\n",
       "      <td>I have always been interested in native American art, history and culture. The museum is a nice size and can be walked in an afternoon. I bought a membership so that I can go a few more times. I was amazed by the diversity of artists and tribes represented at the museum. In one gallery, there was an exhibit by an Inuit artist. In another gallery, there was an exhibition by a Navajo metal smith and jewelry maker. There is a great blending of the ancient native world with the modern native culture. \\n\\nI was going to bypass the interactive displays for the children, but found as I walked them that they were meaningful for adults too. \\n\\nDon't miss the Kachina display or the very sad and moving installation about the native American schools where young people were taken to be \\\"civilized\\\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Bally's reminds me a little more of old school Vegas now that it is getting \\\"older\\\" compared to the newer, more glamorous hotels on the strip.  Great value for the rooms, and you really don't spend much time in your room anyway.  Wish they would update the rooms though.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5 stars</td>\n",
       "      <td>Love this place.   Egg rolls,  hot and sour soup,  amazing.   You must try this place.   Oh yeah,  take out only and call ahead.   Worth the effort.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ad38c-125c-43b9-b10f-34f73feb00a6",
   "metadata": {},
   "source": [
    "## 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d3ec9c-e2b6-4177-bf36-0be43f09cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfa6c617-1534-4ebf-a583-0993805adea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 stars</td>\n",
       "      <td>Not the best pet store.  Prices not very cheap.  It's very clean though.  Will go back if only I'm in the area.</td>\n",
       "      <td>[101, 1753, 1103, 1436, 11109, 2984, 119, 7510, 1116, 1136, 1304, 10928, 119, 1135, 112, 188, 1304, 4044, 1463, 119, 3100, 1301, 1171, 1191, 1178, 146, 112, 182, 1107, 1103, 1298, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(tokenized_datasets[\"train\"], num_examples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d92959-2a59-4b60-acfd-d482fa082d8d",
   "metadata": {},
   "source": [
    "## 微调模型-加载 BERT 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f5fead-a848-4c1f-af7b-13b621365256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbba451-2aa1-4d1d-b7f7-4eb738f0c16d",
   "metadata": {},
   "source": [
    "### 训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b496d9ea-3678-4c62-9538-3c56582682fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f2240-219e-40c4-a4f4-ce5b50746869",
   "metadata": {},
   "source": [
    "**查看完整超参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abfe88d-adb4-41a4-b55e-060736f763f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=models/bert-base-cased-finetune-yelp/runs/Mar16_20-41-32_autodl-container-b4de44b040-27f1536a,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=5,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "output_dir=models/bert-base-cased-finetune-yelp,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=models/bert-base-cased-finetune-yelp,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2394c3-7c8f-495f-aebd-38f67cfad7b2",
   "metadata": {},
   "source": [
    "## 训练过程中指标参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734e9975-9ca8-4906-993d-606570dbcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50cd519f-a1c9-4b02-8ad3-d88eb6f4ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_dir,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  per_device_train_batch_size=32,\n",
    "                                  num_train_epochs=5,\n",
    "                                  logging_steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155cb27-5ff8-48e6-b101-fdcbf3006445",
   "metadata": {},
   "source": [
    "# 开始训练\n",
    "## 实例化训练器（Trainer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf1827b-2de6-4192-bdf9-e80826dded4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd522b46-40a8-484d-ac83-0b567e89d1eb",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dfae95b-e389-4779-b733-df56962cb2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='101566' max='101565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101565/101565 11:46:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.737130</td>\n",
       "      <td>0.681740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.684900</td>\n",
       "      <td>0.713017</td>\n",
       "      <td>0.689240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.618300</td>\n",
       "      <td>0.715907</td>\n",
       "      <td>0.690760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.776169</td>\n",
       "      <td>0.687100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4930' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4930/6250 03:13 < 00:51, 25.51 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646149e4-d266-444f-9d14-daa0cacea9fd",
   "metadata": {},
   "source": [
    "**训练中 GPU内存占用情况**\n",
    "\n",
    "```shell\n",
    "Sat Mar 16 17:12:39 2024\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:CA:00.0 Off |                  Off |\n",
    "| 36%   64C    P2             364W / 450W |  22547MiB / 24564MiB |    100%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|\n",
    "+---------------------------------------------------------------------------------------+\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d24a2-97f5-4382-8c79-6ca40afeb149",
   "metadata": {},
   "source": [
    "**用测试集再评估下试试看**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d66059-a54a-49b4-af8c-e589727a719e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 04:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9002254605293274,\n",
       " 'eval_accuracy': 0.68068,\n",
       " 'eval_runtime': 245.1018,\n",
       " 'eval_samples_per_second': 203.997,\n",
       " 'eval_steps_per_second': 25.5,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9ea86-b436-4618-916f-33ffee2bbe81",
   "metadata": {},
   "source": [
    "## 保存模型和训练状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80d57043-c0b2-4788-8a91-b6dcf311cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b04ec8b0-806e-40e5-9550-89e626aba4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02225f-9063-47a4-b5b6-883e5b1daf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
